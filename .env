# Configuration for the LLM service
LLM_BASE_URL=http://model-runner.docker.internal:12434/engines/llama.cpp/v1

# Configuration for the model to use
LLM_MODEL_NAME=ai/llama3.2:1B-Q4_0
# LLM_MODEL_NAME=ai/llama3.2:1B-Q8_0
# LLM_MODEL_NAME=ai/smollm2